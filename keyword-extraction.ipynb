{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pembuka "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog ini akan membahas teknik sederhana untuk *keyword extraction* atau ekstraksi kata kunci dari dokumen teks. \n",
    "Salah satu aplikasi dari *keyword extraction* bisa anda lihat di bagian bawah dari \n",
    "berita [detik.com](detik.com). Di setiap artikel dari detik.com tertulis keyword-keyword\n",
    "yang diambil dari teks berita. Gambar dibawah merupakan contoh yang diambil dari artikel [ini](https://oto.detik.com/mobil/d-4748247/resmi-ini-tampang-toyota-yaris-terbaru-bisa-parkir-sendiri).\n",
    "\n",
    "![keyword yang muncul di detik.com](keyword-detik.jpg)\n",
    "\n",
    "Dari contoh diatas bisa kita lihat bahwa *keyword* atau kata kunci yang diekstrak dari teks berita detik diatas bisa menjadi *rangkuman* isi dari berita. Kita bisa simpulkan bahwa artikel diatas membahas tentang toyota yaris tanpa perlu membaca seluruh isi teks. Hal ini menjadi salah satu kegunaan utama dari aplikasi *keyword extraction*.\n",
    "\n",
    "Nah, di blog ini saya akan coba membahas satu teknik ekstraksi kata kunci atau *keyword extraction* bahasa Indonesia dari dokumen teks. Idenya sederhana: kita hanya memperhitungkan kata kunci yang berjenis *kata benda* atau *frasa benda*. Dari daftar kata/frasa benda yang kita dapatkan, kita ambil beberapa kata/frasa benda yang *penting* saja, karena dari sebuah dokumen sangat mungkin kita mendapatkan ratusan kata/frasa benda, dan tidak mungkin kita mengambil semua kata/frasa benda tersebut menjadi kata kunci. \n",
    "Dari sini kita bisa tarik dua pertanyaan besar:\n",
    "\n",
    "* Bagaimana cara kita mengambil kata/frasa benda dari teks?\n",
    "* Bagaimana kita mengukur kepentingan dari sebuah kata/frasa benda?\n",
    "\n",
    "Dua pertanyaan diatas yang akan menjadi topik utama di blog ini.\n",
    "\n",
    "Implementasi teknik *keyword extraction* ini saya buat menggunakan Python dalam format Jupyter notebook.\n",
    "Notebook tersebut dapat anda temukan di repo [github](https://github.com/bagasabisena/keyword-extraction) saya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda memerlukan *library* python `jupyter`, `stanfordnlp`, dan `nltk` untuk menjalankan proyek ini.\n",
    "Semua bisa anda *install* menggunakan pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install jupyter\n",
    "pip install stanfordnlp\n",
    "pip install nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sebelum kita mulai, kita perlu mengunduh *file* model bahasa Indonesia yang diperlukan untuk menjalankan fungsi stanfordnlp. Buka terminal di komputer anda dan jalankan perintah berikut\n",
    "\n",
    "```\n",
    "python -c \"import stanfordnlp;stanfordnlp.download('id')\"\n",
    "```\n",
    "\n",
    "Selain itu, kita juga membutuhkan korpus `stopwords` dari NLTK\n",
    "\n",
    "```\n",
    "python -m nltk.downloader stopwords\n",
    "```\n",
    "\n",
    "Sekarang kita bisa mulai dengan mengimpor *module* yang diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"\n",
    "Pemberi kerja adalah orang perseorangan, pengusaha, badan hukum, atau badan-badan lainnya yang mempekerjakan tenaga kerja dengan membayar upah atau imbalan dalam bentuk lain.\n",
    "Pengusaha adalah orang perseorangan, persekutuan, atau badan hukum yang menjalankan suatu perusahaan milik sendiri.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/bagas/stanfordnlp_resources/id_gsd_models/id_gsd_tokenizer.pt', 'lang': 'id', 'shorthand': 'id_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/bagas/stanfordnlp_resources/id_gsd_models/id_gsd_tagger.pt', 'pretrain_path': '/Users/bagas/stanfordnlp_resources/id_gsd_models/id_gsd.pretrain.pt', 'lang': 'id', 'shorthand': 'id_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/bagas/stanfordnlp_resources/id_gsd_models/id_gsd_lemmatizer.pt', 'lang': 'id', 'shorthand': 'id_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/bagas/stanfordnlp_resources/id_gsd_models/id_gsd_parser.pt', 'pretrain_path': '/Users/bagas/stanfordnlp_resources/id_gsd_models/id_gsd.pretrain.pt', 'lang': 'id', 'shorthand': 'id_gsd', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(lang='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<stanfordnlp.pipeline.doc.Sentence at 0x132313d90>,\n",
       " <stanfordnlp.pipeline.doc.Sentence at 0x1098fdd50>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stanfordnlp.pipeline.doc.Sentence at 0x132313d90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Word index=1;text=Pemberi;lemma=penberi;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=4;dependency_relation=nsubj>,\n",
       " <Word index=2;text=kerja;lemma=kerja;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=1;dependency_relation=compound>,\n",
       " <Word index=3;text=adalah;lemma=adalah;upos=AUX;xpos=O--;feats=_;governor=4;dependency_relation=cop>,\n",
       " <Word index=4;text=orang;lemma=orang;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=0;dependency_relation=root>,\n",
       " <Word index=5;text=perseorangan;lemma=perseorangan;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=4;dependency_relation=compound>,\n",
       " <Word index=6;text=,;lemma=,;upos=PUNCT;xpos=Z--;feats=_;governor=7;dependency_relation=punct>,\n",
       " <Word index=7;text=pengusaha;lemma=penusaha;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=4;dependency_relation=conj>,\n",
       " <Word index=8;text=,;lemma=,;upos=PUNCT;xpos=Z--;feats=_;governor=9;dependency_relation=punct>,\n",
       " <Word index=9;text=badan;lemma=badan;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=4;dependency_relation=conj>,\n",
       " <Word index=10;text=hukum;lemma=hukum;upos=NOUN;xpos=VSA;feats=Number=Sing|Voice=Act;governor=9;dependency_relation=compound>,\n",
       " <Word index=11;text=,;lemma=,;upos=PUNCT;xpos=Z--;feats=_;governor=13;dependency_relation=punct>,\n",
       " <Word index=12;text=atau;lemma=atau;upos=CCONJ;xpos=H--;feats=_;governor=13;dependency_relation=cc>,\n",
       " <Word index=13;text=badan-badan;lemma=badan;upos=NOUN;xpos=NPD;feats=Number=Plur;governor=4;dependency_relation=conj>,\n",
       " <Word index=14;text=lainnya;lemma=lainnya;upos=ADJ;xpos=D--;feats=_;governor=13;dependency_relation=amod>,\n",
       " <Word index=15;text=yang;lemma=yang;upos=PRON;xpos=S--;feats=PronType=Rel;governor=16;dependency_relation=nsubj>,\n",
       " <Word index=16;text=mempekerjakan;lemma=menpekerjakan;upos=VERB;xpos=VSA;feats=Number=Sing|Voice=Act;governor=13;dependency_relation=acl>,\n",
       " <Word index=17;text=tenaga;lemma=tenaga;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=16;dependency_relation=obj>,\n",
       " <Word index=18;text=kerja;lemma=kerja;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=17;dependency_relation=compound>,\n",
       " <Word index=19;text=dengan;lemma=dengan;upos=ADP;xpos=R--;feats=_;governor=20;dependency_relation=case>,\n",
       " <Word index=20;text=membayar;lemma=menbayar;upos=VERB;xpos=VSA;feats=Number=Sing|Voice=Act;governor=16;dependency_relation=xcomp>,\n",
       " <Word index=21;text=upah;lemma=upah;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=20;dependency_relation=obj>,\n",
       " <Word index=22;text=atau;lemma=atau;upos=CCONJ;xpos=H--;feats=_;governor=23;dependency_relation=cc>,\n",
       " <Word index=23;text=imbalan;lemma=imbalan;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=21;dependency_relation=conj>,\n",
       " <Word index=24;text=dalam;lemma=dalam;upos=ADP;xpos=ASP;feats=Degree=Pos|Number=Sing;governor=25;dependency_relation=case>,\n",
       " <Word index=25;text=bentuk;lemma=bentuk;upos=NOUN;xpos=NSD;feats=Number=Sing;governor=23;dependency_relation=nmod>,\n",
       " <Word index=26;text=lain;lemma=lain;upos=ADJ;xpos=ASP;feats=Degree=Pos|Number=Sing;governor=25;dependency_relation=amod>,\n",
       " <Word index=27;text=.;lemma=.;upos=PUNCT;xpos=Z--;feats=_;governor=4;dependency_relation=punct>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0].words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pemberi NOUN\n",
      "kerja NOUN\n",
      "adalah AUX\n",
      "orang NOUN\n",
      "perseorangan NOUN\n",
      ", PUNCT\n",
      "pengusaha NOUN\n",
      ", PUNCT\n",
      "badan NOUN\n",
      "hukum NOUN\n",
      ", PUNCT\n",
      "atau CCONJ\n",
      "badan-badan NOUN\n",
      "lainnya ADJ\n",
      "yang PRON\n",
      "mempekerjakan VERB\n",
      "tenaga NOUN\n",
      "kerja NOUN\n",
      "dengan ADP\n",
      "membayar VERB\n",
      "upah NOUN\n",
      "atau CCONJ\n",
      "imbalan NOUN\n",
      "dalam ADP\n",
      "bentuk NOUN\n",
      "lain ADJ\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for word in doc.sentences[0].words:\n",
    "    print(word.text, word.upos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = []\n",
    "for sentence in doc.sentences:\n",
    "    tagged = []\n",
    "    for word in sentence.words:\n",
    "        tagged.append((word.text, word.upos))\n",
    "    tagged_words.append(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pemberi', 'NOUN'),\n",
       "  ('kerja', 'NOUN'),\n",
       "  ('adalah', 'AUX'),\n",
       "  ('orang', 'NOUN'),\n",
       "  ('perseorangan', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('pengusaha', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('badan', 'NOUN'),\n",
       "  ('hukum', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('atau', 'CCONJ'),\n",
       "  ('badan-badan', 'NOUN'),\n",
       "  ('lainnya', 'ADJ'),\n",
       "  ('yang', 'PRON'),\n",
       "  ('mempekerjakan', 'VERB'),\n",
       "  ('tenaga', 'NOUN'),\n",
       "  ('kerja', 'NOUN'),\n",
       "  ('dengan', 'ADP'),\n",
       "  ('membayar', 'VERB'),\n",
       "  ('upah', 'NOUN'),\n",
       "  ('atau', 'CCONJ'),\n",
       "  ('imbalan', 'NOUN'),\n",
       "  ('dalam', 'ADP'),\n",
       "  ('bentuk', 'NOUN'),\n",
       "  ('lain', 'ADJ'),\n",
       "  ('.', 'PUNCT')],\n",
       " [('Pengusaha', 'PROPN'),\n",
       "  ('adalah', 'AUX'),\n",
       "  ('orang', 'NOUN'),\n",
       "  ('perseorangan', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('persekutuan', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('atau', 'CCONJ'),\n",
       "  ('badan', 'NOUN'),\n",
       "  ('hukum', 'NOUN'),\n",
       "  ('yang', 'PRON'),\n",
       "  ('menjalankan', 'VERB'),\n",
       "  ('suatu', 'DET'),\n",
       "  ('perusahaan', 'NOUN'),\n",
       "  ('milik', 'NOUN'),\n",
       "  ('sendiri', 'ADJ'),\n",
       "  ('.', 'PUNCT')]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<NOUN|PROPN>+ <ADJ>*}\"\n",
    "parser = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Pemberi/NOUN kerja/NOUN)\n",
      "  adalah/AUX\n",
      "  (NP orang/NOUN perseorangan/NOUN)\n",
      "  ,/PUNCT\n",
      "  (NP pengusaha/NOUN)\n",
      "  ,/PUNCT\n",
      "  (NP badan/NOUN hukum/NOUN)\n",
      "  ,/PUNCT\n",
      "  atau/CCONJ\n",
      "  (NP badan-badan/NOUN lainnya/ADJ)\n",
      "  yang/PRON\n",
      "  mempekerjakan/VERB\n",
      "  (NP tenaga/NOUN kerja/NOUN)\n",
      "  dengan/ADP\n",
      "  membayar/VERB\n",
      "  (NP upah/NOUN)\n",
      "  atau/CCONJ\n",
      "  (NP imbalan/NOUN)\n",
      "  dalam/ADP\n",
      "  (NP bentuk/NOUN lain/ADJ)\n",
      "  ./PUNCT)\n"
     ]
    }
   ],
   "source": [
    "parse_tree = parser.parse(tagged_words[0])\n",
    "parse_tree.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Pengusaha/PROPN)\n",
      "  adalah/AUX\n",
      "  (NP orang/NOUN perseorangan/NOUN)\n",
      "  ,/PUNCT\n",
      "  (NP persekutuan/NOUN)\n",
      "  ,/PUNCT\n",
      "  atau/CCONJ\n",
      "  (NP badan/NOUN hukum/NOUN)\n",
      "  yang/PRON\n",
      "  menjalankan/VERB\n",
      "  suatu/DET\n",
      "  (NP perusahaan/NOUN milik/NOUN sendiri/ADJ)\n",
      "  ./PUNCT)\n"
     ]
    }
   ],
   "source": [
    "parse_tree = parser.parse(tagged_words[1])\n",
    "parse_tree.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pemberi kerja', 'orang perseorangan', 'badan hukum', 'tenaga kerja']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we get NP as keywords\n",
    "# by walking on the parse tree\n",
    "# keywords if any of the word doesn't contain stopwords\n",
    "parse_tree = parser.parse(tagged_words[0])\n",
    "keywords = []\n",
    "for subtree in parse_tree.subtrees():\n",
    "    if subtree.label() == 'NP' and len(subtree.leaves()) > 1:\n",
    "        words = [item[0] for item in subtree.leaves()]\n",
    "        # this filters out keywords with stop words\n",
    "        if not bool(set(words).intersection(stopwords.words('indonesian'))):\n",
    "            keywords.append(' '.join([item[0] for item in subtree.leaves()]))\n",
    "            \n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['orang perseorangan', 'badan hukum']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we get NP as keywords\n",
    "# by walking on the parse tree\n",
    "# keywords if any of the word doesn't contain stopwords\n",
    "parse_tree = parser.parse(tagged_words[1])\n",
    "keywords = []\n",
    "for subtree in parse_tree.subtrees():\n",
    "    if subtree.label() == 'NP' and len(subtree.leaves()) > 1:\n",
    "        words = [item[0] for item in subtree.leaves()]\n",
    "        # this filters out keywords with stop words\n",
    "        if not bool(set(words).intersection(stopwords.words('indonesian'))):\n",
    "            keywords.append(' '.join([item[0] for item in subtree.leaves()]))\n",
    "            \n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
